{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600893\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import io\n",
    "\n",
    "#path1 = \"hindi_song\"\n",
    "path = keras.utils.data_utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "\n",
      "\n",
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all! for there are scoffers who maintain that it\n",
      "has fallen, that all dogma lies on the ground--nay more, that it is at\n",
      "its last gasp. but to speak seriously, there are good grounds for hoping\n",
      "that all dogmatizing in philosophy, whatever solemn, whatever conclusive\n",
      "and decided airs it has assumed, may have been only a noble puerilism\n",
      "and tyronism; and probably the time is at hand when it will be once\n",
      "and again understood what has actually sufficed for the basis of such\n",
      "imposing and abso\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(sorted(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ä', 'æ', 'é', 'ë']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c,i)for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '=': 22, '?': 23, '[': 24, ']': 25, '_': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52, 'ä': 53, 'æ': 54, 'é': 55, 'ë': 56}\n"
     ]
    }
   ],
   "source": [
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: ';', 22: '=', 23: '?', 24: '[', 25: ']', 26: '_', 27: 'a', 28: 'b', 29: 'c', 30: 'd', 31: 'e', 32: 'f', 33: 'g', 34: 'h', 35: 'i', 36: 'j', 37: 'k', 38: 'l', 39: 'm', 40: 'n', 41: 'o', 42: 'p', 43: 'q', 44: 'r', 45: 's', 46: 't', 47: 'u', 48: 'v', 49: 'w', 50: 'x', 51: 'y', 52: 'z', 53: 'ä', 54: 'æ', 55: 'é', 56: 'ë'}\n"
     ]
    }
   ],
   "source": [
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we create multidimensional arrays out of the text data that we inputed so that the entire corpus of text is enumerated (is assigned a number instead of a character). This will be used for training and makes everything more coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_char = []\n",
    "for i in range(0,len(text)-40,3):\n",
    "    sentences.append(text[i:i+40])\n",
    "    next_char.append(text[i+40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preface\\n\\n\\nsupposing that truth is a woma', 'face\\n\\n\\nsupposing that truth is a woman--', 'e\\n\\n\\nsupposing that truth is a woman--wha', '\\nsupposing that truth is a woman--what t', 'pposing that truth is a woman--what then', 'sing that truth is a woman--what then? i', 'g that truth is a woman--what then? is t', 'hat truth is a woman--what then? is ther', ' truth is a woman--what then? is there n', 'uth is a woman--what then? is there not ', ' is a woman--what then? is there not gro', ' a woman--what then? is there not ground', 'woman--what then? is there not ground\\nfo', 'an--what then? is there not ground\\nfor s', '-what then? is there not ground\\nfor susp', 'at then? is there not ground\\nfor suspect', 'then? is there not ground\\nfor suspecting', 'n? is there not ground\\nfor suspecting th', 'is there not ground\\nfor suspecting that ', 'there not ground\\nfor suspecting that all', 're not ground\\nfor suspecting that all ph', 'not ground\\nfor suspecting that all philo', ' ground\\nfor suspecting that all philosop', 'ound\\nfor suspecting that all philosopher', 'd\\nfor suspecting that all philosophers, ', 'or suspecting that all philosophers, in ', 'suspecting that all philosophers, in so ', 'pecting that all philosophers, in so far', 'ting that all philosophers, in so far as', 'g that all philosophers, in so far as th', 'hat all philosophers, in so far as they ', ' all philosophers, in so far as they hav', 'l philosophers, in so far as they have b', 'hilosophers, in so far as they have been', 'osophers, in so far as they have been\\ndo', 'phers, in so far as they have been\\ndogma', 'rs, in so far as they have been\\ndogmatis', ' in so far as they have been\\ndogmatists,', ' so far as they have been\\ndogmatists, ha', ' far as they have been\\ndogmatists, have ', 'r as they have been\\ndogmatists, have fai', 's they have been\\ndogmatists, have failed', 'hey have been\\ndogmatists, have failed to', ' have been\\ndogmatists, have failed to un', 've been\\ndogmatists, have failed to under', 'been\\ndogmatists, have failed to understa', 'n\\ndogmatists, have failed to understand ', 'ogmatists, have failed to understand wom', 'atists, have failed to understand women-', 'sts, have failed to understand women--th']\n",
      "___________________________________________________\n",
      "['n', 'w', 't', 'h', '?', 's', 'h', 'e', 'o', 'g', 'u', '\\n', 'r', 'u', 'e', 'i', ' ', 'a', 'a', ' ', 'i', 's', 'h', 's', 'i', 's', 'f', ' ', ' ', 'e', 'h', 'e', 'e', '\\n', 'g', 't', 't', ' ', 'v', 'f', 'l', ' ', ' ', 'd', 's', 'n', 'w', 'e', '-', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:50])\n",
    "print(\"___________________________________________________\")\n",
    "print(next_char[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=np.zeros(40,40,dtype=np.bool)\n",
    "x = np.zeros((len(sentences), 40, len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200285, 40, 57)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200285, 57)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ,sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i,t,char_indices[char]] = 1\n",
    "    y[i,char_indices[next_char[i]]] =1    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200285, 40, 57)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200285, 57)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's build the model with an LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(40, len(chars))))\n",
    "model.add(keras.layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function will compare the sample predictions with the original text. The temperature represents how accurate or confident the model's predictions will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\IamChamp\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "200285/200285 [==============================] - 2037s 10ms/step - loss: 2.0049\n",
      "Epoch 2/10\n",
      "200285/200285 [==============================] - 2100s 10ms/step - loss: 1.8553\n",
      "Epoch 3/10\n",
      "200285/200285 [==============================] - 3181s 16ms/step - loss: 1.8623\n",
      "Epoch 4/10\n",
      "200285/200285 [==============================] - 3908s 20ms/step - loss: 1.8994\n",
      "Epoch 5/10\n",
      " 50040/200285 [======>.......................] - ETA: 53:37 - loss: 1.9647"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=18, epochs=10)\n",
    "start_index = random.randint(0, len(text) - 40 - 1)\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + 40]\n",
    "    generated += sentence\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, 40, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "with open('example4.txt', 'w') as f:\n",
    "    print(generated)\n",
    "    f.write(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
